{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dstYRRIHTB3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c704b1-de70-4587-b38a-d1ea7fc94171"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torch.utils.data import sampler\r\n",
        "import torchvision.datasets as dset\r\n",
        "import torchvision.transforms as T\r\n",
        "import torch.nn.functional as F\r\n",
        "import numpy as np\r\n",
        "import matplotlib as plt\r\n",
        "from matplotlib.pyplot import *\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "NUM_TRAIN = 49000\r\n",
        "cifar_dict = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog','frog','horse','ship','truck' ]\r\n",
        "# The torchvision.transforms package provides tools for preprocessing data\r\n",
        "# and for performing data augmentation; here we set up a transform to\r\n",
        "# preprocess the data by subtracting the mean RGB value and dividing by the\r\n",
        "# standard deviation of each RGB value; we've hardcoded the mean and std.\r\n",
        "transform = T.Compose([\r\n",
        "                T.ToTensor(),\r\n",
        "                T.Normalize((0.4914), (0.2023))\r\n",
        "            ])\r\n",
        "\r\n",
        "# We set up a Dataset object for each split (train / val / test); Datasets load\r\n",
        "# training examples one at a time, so we wrap each Dataset in a DataLoader which\r\n",
        "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\r\n",
        "# training set into train and val sets by passing a Sampler object to the\r\n",
        "# DataLoader telling how it should sample from the underlying Dataset.\r\n",
        "cifar10_train = dset.CIFAR10(\r\n",
        "    './cs231n/datasets',\r\n",
        "    train=True, download=True,\r\n",
        "    transform=transform\r\n",
        ")\r\n",
        "loader_train = DataLoader(\r\n",
        "    cifar10_train,\r\n",
        "    batch_size=64,\r\n",
        "    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN))\r\n",
        ")\r\n",
        "cifar10_val = dset.CIFAR10(\r\n",
        "    './cs231n/datasets',\r\n",
        "    train=True, download=True,\r\n",
        "    transform=transform\r\n",
        ")\r\n",
        "loader_val = DataLoader(\r\n",
        "    cifar10_val, batch_size=64, \r\n",
        "    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000))\r\n",
        ")\r\n",
        "\r\n",
        "cifar10_test = dset.CIFAR10(\r\n",
        "    './cs231n/datasets',\r\n",
        "    train=False, download=True,\r\n",
        "    transform=transform\r\n",
        ")\r\n",
        "loader_test = DataLoader(cifar10_test, batch_size=64)\r\n",
        "\r\n",
        "def flatten(x):\r\n",
        "    N = x.shape[0] # read in N, C, H, W\r\n",
        "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\r\n",
        "\r\n",
        "def train_part34(model, optimizer, epochs=1):\r\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\r\n",
        "    for e in range(epochs):\r\n",
        "        for t, (x, y) in enumerate(loader_train):\r\n",
        "            model.train()  # put model to training mode\r\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\r\n",
        "            y = y.to(device=device, dtype=torch.long)\r\n",
        "\r\n",
        "            scores = model(x)\r\n",
        "            loss = F.cross_entropy(scores, y)\r\n",
        "\r\n",
        "            # Zero out all of the gradients for the variables which the optimizer\r\n",
        "            # will update.\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            # This is the backwards pass: compute the gradient of the loss with\r\n",
        "            # respect to each  parameter of the model.\r\n",
        "            loss.backward()\r\n",
        "\r\n",
        "            # Actually update the parameters of the model using the gradients\r\n",
        "            # computed by the backwards pass.\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            if t % print_every == 0:\r\n",
        "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\r\n",
        "                check_accuracy_part34(loader_val, model)\r\n",
        "                print()\r\n",
        "def check_accuracy_part34(loader, model):\r\n",
        "    if loader.dataset.train:\r\n",
        "        print('Checking accuracy on validation set')\r\n",
        "    else:\r\n",
        "        print('Checking accuracy on test set')   \r\n",
        "    num_correct = 0\r\n",
        "    num_samples = 0\r\n",
        "    model.eval()  # set model to evaluation mode\r\n",
        "    with torch.no_grad():\r\n",
        "        for x, y in loader:\r\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\r\n",
        "            y = y.to(device=device, dtype=torch.long)\r\n",
        "            scores = model(x)\r\n",
        "            _, preds = scores.max(1)\r\n",
        "            num_correct += (preds == y).sum()\r\n",
        "            num_samples += preds.size(0)\r\n",
        "        acc = float(num_correct) / num_samples\r\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\r\n",
        "def predict(loader, model):\r\n",
        "    model.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        for x, y in loader:\r\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\r\n",
        "            y = y.to(device=device, dtype=torch.long)\r\n",
        "            scores = model(x)\r\n",
        "            grid = np.concatenate([np.swapaxes(np.swapaxes(x[i].cpu().reshape(3,32,32),0,1),1,2) for i in range(10)], axis = 1)\r\n",
        "            imshow(grid)\r\n",
        "            final_pred = torch.argmax(scores,axis = 1)[:10].cpu()\r\n",
        "            for i in final_pred:\r\n",
        "              print(cifar_dict[i], end = \" \")\r\n",
        "            print()\r\n",
        "            plt.show()\r\n",
        "#fix this\r\n",
        "class Dblock(nn.Module):\r\n",
        "    def __init__(self, in_planes, planes):\r\n",
        "        super(Dblock, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, 3, padding =1)\r\n",
        "        self.conv2 = nn.Conv2d(planes, planes, 3, padding =1)\r\n",
        "        self.conv3 = nn.Conv2d(planes, planes, 3, padding =1)\r\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\r\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\r\n",
        "        self.bn3 = nn.BatchNorm2d(planes)\r\n",
        "        self.shortcut = nn.Sequential()\r\n",
        "        if (in_planes != planes):\r\n",
        "            self.shortcut = nn.Sequential(\r\n",
        "                nn.Conv2d(in_planes,planes,3,padding = 1),\r\n",
        "                nn.BatchNorm2d(planes)        \r\n",
        "            )\r\n",
        "    def forward(self,x):\r\n",
        "        out1 = self.conv1(F.relu(self.bn1(x)))\r\n",
        "        out2 = self.conv2(F.relu(self.bn1(self.shortcut(out1) + self.shortcut(x))))\r\n",
        "        out3 = self.conv3(F.relu(self.bn1(self.shortcut(out2) + self.shortcut(out1) + self.shortcut(x))))\r\n",
        "        return out3\r\n",
        "class Block(nn.Module):\r\n",
        "    def __init__(self, in_planes, planes):\r\n",
        "        super(Block, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, 3, padding =1)\r\n",
        "        self.conv2 = nn.Conv2d(planes, planes, 3, padding =1)\r\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\r\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\r\n",
        "        self.shortcut = nn.Sequential()\r\n",
        "        if (in_planes != planes):\r\n",
        "            self.shortcut = nn.Sequential(\r\n",
        "                nn.Conv2d(in_planes,planes,3,padding = 1),\r\n",
        "                nn.BatchNorm2d(planes)\r\n",
        "            )\r\n",
        "    def forward(self,x):\r\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\r\n",
        "        out = F.relu(self.bn2(self.conv2(out)) + self.shortcut(x))\r\n",
        "        return out\r\n",
        "class ResNet(nn.Module):\r\n",
        "    def __init__(self,in_channels, hidden_channels, num_classes):\r\n",
        "        super(ResNet, self).__init__()\r\n",
        "        self.conv = nn.Conv2d(in_channels, hidden_channels[0], 3, padding = 1)\r\n",
        "        self.bn = nn.BatchNorm2d(hidden_channels[0])\r\n",
        "        self.res1 = Block(hidden_channels[0], hidden_channels[1])\r\n",
        "        self.res2 = Block(hidden_channels[1], hidden_channels[2])\r\n",
        "        self.res3 = Block(hidden_channels[2], hidden_channels[3])\r\n",
        "        self.maxpool = nn.MaxPool2d(2,2)\r\n",
        "        self.fc = nn.Linear(hidden_channels[3]*16*16, num_classes)\r\n",
        "    def forward(self,x):\r\n",
        "        out = F.relu(self.bn(self.conv(x)))\r\n",
        "        out = self.res1(out)\r\n",
        "        out = self.res2(out)\r\n",
        "        out = self.res3(out)\r\n",
        "        out = self.maxpool(out)\r\n",
        "        out = self.fc(flatten(out))\r\n",
        "        return out\r\n",
        "\r\n",
        "def train(model, optimizer, loader_train, loader_val, print_every = 100,epochs=1):\r\n",
        "    model = model.to(device=device)\r\n",
        "    for e in range(epochs):\r\n",
        "        for t, (x, y) in enumerate(loader_train):\r\n",
        "            model.train()\r\n",
        "            x = x.to(device=device, dtype = dtype)\r\n",
        "            y = y.to(device=device, dtype = torch.long)\r\n",
        "            scores = model(x)\r\n",
        "            loss = F.cross_entropy(scores,y)\r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            if t % print_every == 0:\r\n",
        "                print('Iteration %d, loss = %.4f'%(t,loss.item()))\r\n",
        "                check(loader_val,model)\r\n",
        "                print()\r\n",
        "def check(loader, model):\r\n",
        "    num_correct = 0\r\n",
        "    num_samples = 0\r\n",
        "    model.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        for x,y in loader:\r\n",
        "            x = x.to(device=device, dtype=dtype)\r\n",
        "            y = y.to(device=device, dtype=torch.long)\r\n",
        "            scores = model(x)\r\n",
        "            _, preds = scores.max(1)\r\n",
        "            num_correct+= (preds==y).sum()\r\n",
        "            num_samples+= preds.size(0)\r\n",
        "        acc = float(num_correct)/num_samples\r\n",
        "        print('Got %d / %d correct (%.2f)'%(num_correct, num_samples, 100*acc))\r\n",
        "class block(nn.Module): \r\n",
        "    def __init__(self, in_planes, planes):\r\n",
        "        super(block, self).__init__()\r\n",
        "        #conv-bn-shortcut\r\n",
        "        self.conv1 = nn.Conv2d(in_planes,planes,3, padding=1)\r\n",
        "        self.conv2 = nn.Conv2d(planes,planes,3, padding=1)\r\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\r\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\r\n",
        "        self.shortcut = nn.Sequential()\r\n",
        "        if planes != in_planes:\r\n",
        "            self.shortcut = nn.Sequential(\r\n",
        "                nn.Conv2d(in_planes,planes,3, padding=1),\r\n",
        "                nn.BatchNorm2d(planes)\r\n",
        "                ) \r\n",
        "    def forward(self,x):\r\n",
        "        out = F.relu((self.bn1(self.conv1(x))))\r\n",
        "        out = F.relu((self.bn2(self.conv2(out)))+ self.shortcut(x))\r\n",
        "        return out\r\n",
        "class resNet(nn.Module):\r\n",
        "    def __init__(self,in_channels,hidden_channels,num_classes, width = 32, height = 32):\r\n",
        "        super(resNet,self).__init__()\r\n",
        "        self.conv = nn.Conv2d(in_channels,hidden_channels[0], 3, padding=1)\r\n",
        "        self.bn = nn.BatchNorm2d(hidden_channels[0])\r\n",
        "        self.res1 = block(hidden_channels[0],hidden_channels[1])\r\n",
        "        self.res2 = block(hidden_channels[1],hidden_channels[2])\r\n",
        "        self.res3 = block(hidden_channels[2],hidden_channels[3])\r\n",
        "        self.maxpool = nn.MaxPool2d(2,2)\r\n",
        "        self.fc = nn.Linear(hidden_channels[3]*int(width/2)*int(height/2), num_classes)\r\n",
        "    def forward(self,x):\r\n",
        "        out = F.relu(self.bn(self.conv(x)))\r\n",
        "        out = self.res1(out)\r\n",
        "        out = self.res2(out)\r\n",
        "        out = self.res3(out)\r\n",
        "        out = self.maxpool(out)\r\n",
        "        out = self.fc(flatten(out))\r\n",
        "        return out\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qJHVvI5Uktz",
        "outputId": "d26051fa-7f31-443c-8086-6fb6bca87cfe"
      },
      "source": [
        "USE_GPU = True\r\n",
        "\r\n",
        "dtype = torch.float32 # we will be using float throughout this tutorial\r\n",
        "\r\n",
        "if USE_GPU and torch.cuda.is_available():\r\n",
        "    device = torch.device('cuda')\r\n",
        "else:\r\n",
        "    device = torch.device('cpu')\r\n",
        "\r\n",
        "# Constant to control how frequently we print train loss\r\n",
        "print_every = 100\r\n",
        "\r\n",
        "print('using device:', device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54Jxd7T3TXB_"
      },
      "source": [
        "\r\n",
        "hidden_layers = [16,32,64,128]\r\n",
        "model = resNet(3, hidden_layers,10,32,32)\r\n",
        "optimizer = optim.Adam(model.parameters(),lr = 2e-4)\r\n",
        "train(model,optimizer,loader_train, loader_val, epochs = 20)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIjBMevIUWpD",
        "outputId": "39488d5c-8d7c-411b-a55b-a4e8091ae60e"
      },
      "source": [
        "best_model = model\r\n",
        "check(loader_test, best_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Got 7246 / 10000 correct (72.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "APYjQFNhZyMt",
        "outputId": "9facd24e-e8f7-4fab-bfa2-54b0d247837b"
      },
      "source": [
        "best_model = model\r\n",
        "predict(loader_test, best_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZgdq_LWaRB5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}